{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6565fd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\mms_meta_internships\\property_legal_advisor\\venv_310_legal\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting laws...\n",
      "Loaded 6 law documents\n",
      "Chunking...\n",
      "Created 2274 chunks\n",
      "Creating local HF embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Souhar\\AppData\\Local\\Temp\\ipykernel_10032\\3547583878.py:112: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 336.58it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB saved at: ../vector_db\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pypdf import PdfReader\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# ==============================\n",
    "# CONFIG\n",
    "# ==============================\n",
    "\n",
    "ROOT = \"../\"\n",
    "\n",
    "CENTRAL_PATH = os.path.join(ROOT, \"central\")\n",
    "KARNATAKA_PATH = os.path.join(ROOT, \"karnataka\")\n",
    "\n",
    "VECTOR_PATH = os.path.join(ROOT, \"vector_db\")\n",
    "\n",
    "# ==============================\n",
    "# PDF LOADER\n",
    "# ==============================\n",
    "\n",
    "def load_pdf_text(path):\n",
    "\n",
    "    reader = PdfReader(path)\n",
    "    text = \"\"\n",
    "\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "\n",
    "    return text\n",
    "\n",
    "# ==============================\n",
    "# COLLECT LAW DOCUMENTS\n",
    "# ==============================\n",
    "\n",
    "def collect_law_documents():\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # ---- CENTRAL LAWS ----\n",
    "    for file in os.listdir(CENTRAL_PATH):\n",
    "        if file.endswith(\".pdf\"):\n",
    "\n",
    "            full_path = os.path.join(CENTRAL_PATH, file)\n",
    "            text = load_pdf_text(full_path)\n",
    "\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    page_content=text,\n",
    "                    metadata={\n",
    "                        \"law_type\": \"central\",\n",
    "                        \"source\": file\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # ---- KARNATAKA LAWS ----\n",
    "    for file in os.listdir(KARNATAKA_PATH):\n",
    "        if file.endswith(\".pdf\"):\n",
    "\n",
    "            full_path = os.path.join(KARNATAKA_PATH, file)\n",
    "            text = load_pdf_text(full_path)\n",
    "\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    page_content=text,\n",
    "                    metadata={\n",
    "                        \"law_type\": \"karnataka\",\n",
    "                        \"source\": file\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return documents\n",
    "\n",
    "# ==============================\n",
    "# CHUNKING\n",
    "# ==============================\n",
    "\n",
    "def chunk_documents(documents):\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=700,       # better for legal text\n",
    "        chunk_overlap=120\n",
    "    )\n",
    "\n",
    "    return splitter.split_documents(documents)\n",
    "\n",
    "# ==============================\n",
    "# BUILD VECTOR DATABASE\n",
    "# ==============================\n",
    "\n",
    "def build_vector_db():\n",
    "\n",
    "    print(\"Collecting laws...\")\n",
    "    docs = collect_law_documents()\n",
    "\n",
    "    print(f\"Loaded {len(docs)} law documents\")\n",
    "\n",
    "    print(\"Chunking...\")\n",
    "    chunks = chunk_documents(docs)\n",
    "\n",
    "    print(f\"Created {len(chunks)} chunks\")\n",
    "\n",
    "    print(\"Creating local HF embeddings...\")\n",
    "\n",
    "    # LOCAL EMBEDDINGS (NO API KEY)\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "\n",
    "    db = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "    db.save_local(VECTOR_PATH)\n",
    "\n",
    "    print(\"Vector DB saved at:\", VECTOR_PATH)\n",
    "\n",
    "# ==============================\n",
    "# RUN\n",
    "# ==============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_vector_db()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb3166",
   "metadata": {},
   "source": [
    "## Loading the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "761de605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 184.81it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "db = FAISS.load_local(\n",
    "    \"../vector_db\",\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cef218",
   "metadata": {},
   "source": [
    "takes 7 sec avg to load db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5bf4d1",
   "metadata": {},
   "source": [
    "# Legal Law Vector Database – Handover Summary\n",
    "\n",
    "1. This vector database is used for **legal compliance retrieval** and contains embeddings built from **Central law PDFs** and **Karnataka law PDFs** only (no templates or extracted JSONs). \n",
    "\n",
    "2. The embeddings were generated using **sentence-transformers/all-MiniLM-L6-v2**, and the same model **must** be used when loading the DB, otherwise similarity search will fail. \n",
    "\n",
    "3. The database files are `index.faiss` and `index.pkl`, both required together. Load the DB using HuggingFaceEmbeddings with the same model and FAISS `load_local()`.\n",
    "\n",
    "4. Chunking settings used during creation: `chunk_size = 700`, `chunk_overlap = 120`; rebuilding with different settings changes retrieval behavior. \n",
    "\n",
    "5. First run downloads the MiniLM model (~90MB), after which everything runs locally and offline (no HuggingFace API key required). Do not rebuild the vector DB unless law PDFs change. Correct usage is to generate **legal queries** from extracted JSON and run similarity search; do not send full JSON directly into vector search. This DB is strictly a semantic retrieval layer — Gemini only reads retrieved text, not embeddings.\n",
    "\n",
    "6. Required packages: pip install sentence-transformers langchain-core langchain-community langchain-text-splitters faiss-cpu pypdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24942d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_310_legal (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

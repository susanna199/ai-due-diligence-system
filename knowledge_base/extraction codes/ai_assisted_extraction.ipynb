{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db70173a",
   "metadata": {},
   "source": [
    "## EC json extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b7c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting header...\n",
      "Extracting summary...\n",
      "Extracting mutations...\n",
      "Saved: ../templates/ec\\ec_extracted.json\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "# ==============================\n",
    "# CONFIG\n",
    "# ==============================\n",
    "\n",
    "#------------ENTER YOUR API KEY HERE----------------\n",
    "# API_KEY=....\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash\"\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    MODEL_NAME,\n",
    "    generation_config={\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.1\n",
    "    }\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# JSON CLEANER\n",
    "# ==============================\n",
    "\n",
    "def clean_json_response(text):\n",
    "    if not text:\n",
    "        raise ValueError(\"Empty response\")\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    text = re.sub(r\"```json\", \"\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"```\", \"\", text).strip()\n",
    "\n",
    "    # Try direct parse\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Try list extraction\n",
    "    list_start = text.find(\"[\")\n",
    "    list_end = text.rfind(\"]\")\n",
    "\n",
    "    if list_start != -1 and list_end != -1:\n",
    "        try:\n",
    "            return json.loads(text[list_start:list_end+1])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Try object extraction\n",
    "    obj_start = text.find(\"{\")\n",
    "    obj_end = text.rfind(\"}\")\n",
    "\n",
    "    if obj_start != -1 and obj_end != -1:\n",
    "        candidate = text[obj_start:obj_end+1]\n",
    "        decoder = json.JSONDecoder()\n",
    "        idx = 0\n",
    "        objs = []\n",
    "\n",
    "        while idx < len(candidate):\n",
    "            part = candidate[idx:].lstrip()\n",
    "            if not part:\n",
    "                break\n",
    "            obj, end = decoder.raw_decode(part)\n",
    "            objs.append(obj)\n",
    "            idx += len(candidate[idx:]) - len(part) + end\n",
    "\n",
    "        if len(objs) == 1:\n",
    "            return objs[0]\n",
    "        elif len(objs) > 1:\n",
    "            return objs\n",
    "\n",
    "    raise ValueError(\"Could not parse JSON\")\n",
    "\n",
    "# ==============================\n",
    "# NORMALIZATION (VERY IMPORTANT)\n",
    "# ==============================\n",
    "\n",
    "def normalize_keys(obj):\n",
    "    rename_map = {\n",
    "        \"survey_not_reliable\": \"survey_no\",\n",
    "        \"the_evil_one\": \"judi\",\n",
    "        \"bad_news\": \"sessu\"\n",
    "    }\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        new_obj = {}\n",
    "        for k, v in obj.items():\n",
    "            new_key = rename_map.get(k, k)\n",
    "            new_obj[new_key] = normalize_keys(v)\n",
    "        return new_obj\n",
    "\n",
    "    if isinstance(obj, list):\n",
    "        return [normalize_keys(i) for i in obj]\n",
    "\n",
    "    return obj\n",
    "\n",
    "# ==============================\n",
    "# FINAL POST-PROCESS FIX\n",
    "# ==============================\n",
    "\n",
    "def clean_account_change_entries(mutations):\n",
    "    \"\"\"\n",
    "    SAFE FIX:\n",
    "    - split transferee + relationship\n",
    "    - merge ONLY clear continuation rows\n",
    "    - NEVER delete anchor rows\n",
    "    \"\"\"\n",
    "\n",
    "    for mutation in mutations:\n",
    "\n",
    "        entries = mutation.get(\"account_change_entries\", [])\n",
    "        if not entries:\n",
    "            continue\n",
    "\n",
    "        cleaned = []\n",
    "\n",
    "        for entry in entries:\n",
    "\n",
    "            survey = entry.get(\"affected_survey_and_share_number\")\n",
    "            rights = entry.get(\"those_who_changed_their_rights\")\n",
    "            area = entry.get(\"area_changed_rights\")\n",
    "            transferees = entry.get(\"transferees\", [])\n",
    "\n",
    "            # ---- split name + relationship ----\n",
    "            for t in transferees:\n",
    "                if \"transferee\" in t and isinstance(t[\"transferee\"], str):\n",
    "                    txt = t[\"transferee\"]\n",
    "\n",
    "                    if \"Relationship\" in txt:\n",
    "                        parts = txt.split(\"Relationship\")\n",
    "                        t[\"name\"] = parts[0].replace(\":\", \"\").strip()\n",
    "                        t[\"relationship\"] = parts[1].replace(\":\", \"\").strip()\n",
    "                        del t[\"transferee\"]\n",
    "\n",
    "            # ---- SAFE MERGE LOGIC ----\n",
    "            if cleaned:\n",
    "\n",
    "                last = cleaned[-1]\n",
    "\n",
    "                same_survey = (\n",
    "                    survey is not None and\n",
    "                    survey == last.get(\"affected_survey_and_share_number\")\n",
    "                )\n",
    "\n",
    "                continuation_row = (\n",
    "                    rights is None and\n",
    "                    area is None and\n",
    "                    transferees\n",
    "                )\n",
    "\n",
    "                # ONLY merge obvious continuation rows\n",
    "                if same_survey and continuation_row:\n",
    "                    last.setdefault(\"transferees\", [])\n",
    "                    last[\"transferees\"].extend(transferees)\n",
    "                    continue\n",
    "\n",
    "            # NEVER remove real rows\n",
    "            cleaned.append(entry)\n",
    "\n",
    "        mutation[\"account_change_entries\"] = cleaned\n",
    "\n",
    "    return mutations\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# HELPERS\n",
    "# ==============================\n",
    "\n",
    "def load_pdf_bytes(pdf_path):\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(pdf_path)\n",
    "\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def call_gemini(pdf_data, prompt):\n",
    "    response = model.generate_content([\n",
    "        {\"mime_type\": \"application/pdf\", \"data\": pdf_data},\n",
    "        prompt\n",
    "    ])\n",
    "    return response.text.strip()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# PROMPTS\n",
    "# ==============================\n",
    "\n",
    "HEADER_PROMPT = \"\"\"\n",
    "Extract ONLY document metadata from the top of the EC report.\n",
    "\n",
    "Return:\n",
    "\n",
    "{\n",
    "  \"document_metadata\": {\n",
    "    \"report_title\": null,\n",
    "    \"district\": null,\n",
    "    \"taluk\": null,\n",
    "    \"hobli\": null,\n",
    "    \"village\": null,\n",
    "    \"survey_no_main\": null\n",
    "  }\n",
    "}\n",
    "\n",
    "Ignore mutation tables.\n",
    "Output JSON only.\n",
    "\"\"\"\n",
    "\n",
    "SUMMARY_PROMPT = \"\"\"\n",
    "Extract ONLY mutation summary table.\n",
    "\n",
    "Return:\n",
    "\n",
    "{\n",
    "  \"mutation_summary\":[\n",
    "    {\n",
    "      \"si_no\": null,\n",
    "      \"mr_number\": null,\n",
    "      \"mutation_type\": null\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Output JSON only.\n",
    "\"\"\"\n",
    "\n",
    "MUTATION_PROMPT = \"\"\"\n",
    "Extract ALL mutation sections from this EC.\n",
    "\n",
    "IMPORTANT RULES:\n",
    "\n",
    "- Each mutation begins with \"SI NO\".\n",
    "- Extract ALL mutations.\n",
    "- Preserve hierarchy.\n",
    "\n",
    "SCHEMA RULE (STRICT):\n",
    "\n",
    "Use these key names ONLY:\n",
    "- survey_no\n",
    "- judi\n",
    "- sessu\n",
    "- water_rate\n",
    "- revenue\n",
    "\n",
    "Never output:\n",
    "- survey_not_reliable\n",
    "- the_evil_one\n",
    "- bad_news\n",
    "\n",
    "Return:\n",
    "\n",
    "{\n",
    "  \"mutations\":[\n",
    "    {\n",
    "      \"si_no\": null,\n",
    "      \"change_method\": null,\n",
    "      \"acquisition_method\": null,\n",
    "      \"mr_number\": null,\n",
    "      \"approve_date\": null,\n",
    "      \"mutation_status\": null,\n",
    "      \"account_change_entries\": [],\n",
    "      \"new_survey_details\": [],\n",
    "      \"owner_details\": []\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "ROW INHERITANCE RULE:\n",
    "\n",
    "If a row has NULL or blank values for:\n",
    "- affected_survey_and_share_number\n",
    "- those_who_changed_their_rights\n",
    "- area_changed_rights\n",
    "\n",
    "then it belongs to the PREVIOUS non-empty row.\n",
    "\n",
    "Group such rows as transferees under the previous survey entry.\n",
    "\n",
    "Do NOT output separate objects with null survey numbers.\n",
    "\n",
    "\n",
    "Output JSON only.\n",
    "\"\"\"\n",
    "\n",
    "# ==============================\n",
    "# EXTRACTION FUNCTIONS\n",
    "# ==============================\n",
    "\n",
    "def extract_header(pdf_data):\n",
    "    print(\"Extracting header...\")\n",
    "    result = call_gemini(pdf_data, HEADER_PROMPT)\n",
    "    data = clean_json_response(result)\n",
    "    return data.get(\"document_metadata\", {})\n",
    "\n",
    "\n",
    "def extract_summary(pdf_data):\n",
    "    print(\"Extracting summary...\")\n",
    "    result = call_gemini(pdf_data, SUMMARY_PROMPT)\n",
    "    data = clean_json_response(result)\n",
    "    return data.get(\"mutation_summary\", [])\n",
    "\n",
    "\n",
    "def extract_mutations(pdf_data):\n",
    "    print(\"Extracting mutations...\")\n",
    "    result = call_gemini(pdf_data, MUTATION_PROMPT)\n",
    "    data = clean_json_response(result)\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        return data.get(\"mutations\", [])\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "\n",
    "    return []\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# MAIN PIPELINE\n",
    "# ==============================\n",
    "\n",
    "def run_pipeline(pdf_path):\n",
    "\n",
    "    pdf_data = load_pdf_bytes(pdf_path)\n",
    "\n",
    "    metadata = extract_header(pdf_data)\n",
    "    mutation_summary = extract_summary(pdf_data)\n",
    "    mutations = extract_mutations(pdf_data)\n",
    "\n",
    "    final_json = {\n",
    "        \"document_metadata\": metadata,\n",
    "        \"mutation_summary\": mutation_summary,\n",
    "        \"mutations\": mutations\n",
    "    }\n",
    "\n",
    "    # normalize bad OCR keys\n",
    "    final_json = normalize_keys(final_json)\n",
    "\n",
    "    final_json[\"mutations\"] = clean_account_change_entries(\n",
    "        final_json[\"mutations\"]\n",
    "    )\n",
    "\n",
    "    output_path = os.path.join(\n",
    "        os.path.dirname(pdf_path),\n",
    "        \"ec_extracted.json\"\n",
    "    )\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(final_json, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"Saved:\", output_path)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# RUN\n",
    "# ==============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"../templates/ec/EC_sample.pdf\"\n",
    "    run_pipeline(pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdaf3fc",
   "metadata": {},
   "source": [
    "## Khata Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92e70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting khata data...\n",
      "Saved: ../templates/khata\\khata_extracted.json\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# ==============================\n",
    "# CONFIG\n",
    "# ==============================\n",
    "\n",
    "#------------ENTER YOUR API KEY HERE----------------\n",
    "# API_KEY=....\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash\"\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    MODEL_NAME,\n",
    "    generation_config={\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.1\n",
    "    }\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# JSON CLEANER\n",
    "# ==============================\n",
    "\n",
    "def clean_json_response(text):\n",
    "\n",
    "    if not text:\n",
    "        raise ValueError(\"Empty response\")\n",
    "\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"```json\", \"\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"```\", \"\", text).strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "\n",
    "    if start != -1 and end != -1:\n",
    "        return json.loads(text[start:end+1])\n",
    "\n",
    "    raise ValueError(\"Could not parse JSON\")\n",
    "\n",
    "# ==============================\n",
    "# POST PROCESS (FIXES)\n",
    "# ==============================\n",
    "\n",
    "def clean_khata_output(data):\n",
    "    \"\"\"\n",
    "    Fix:\n",
    "    - move TOTAL row\n",
    "    - keep entries clean\n",
    "    \"\"\"\n",
    "\n",
    "    entries = data.get(\"entries\", [])\n",
    "    cleaned_entries = []\n",
    "    total_row = None\n",
    "\n",
    "    for row in entries:\n",
    "\n",
    "        owner = row.get(\"owner_name\")\n",
    "\n",
    "        if owner and owner.lower().strip() == \"total\":\n",
    "            total_row = row\n",
    "            continue\n",
    "\n",
    "        cleaned_entries.append(row)\n",
    "\n",
    "    data[\"entries\"] = cleaned_entries\n",
    "\n",
    "    if total_row:\n",
    "        data[\"table_summary\"] = total_row\n",
    "    else:\n",
    "        data[\"table_summary\"] = {}\n",
    "\n",
    "    return data\n",
    "\n",
    "# ==============================\n",
    "# HELPERS\n",
    "# ==============================\n",
    "\n",
    "def load_pdf_bytes(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def call_gemini(pdf_data, prompt):\n",
    "    response = model.generate_content([\n",
    "        {\"mime_type\": \"application/pdf\", \"data\": pdf_data},\n",
    "        prompt\n",
    "    ])\n",
    "    return response.text.strip()\n",
    "\n",
    "# ==============================\n",
    "# PROMPT\n",
    "# ==============================\n",
    "\n",
    "KHATA_PROMPT = \"\"\"\n",
    "You are extracting data from a Karnataka\n",
    "\"Copy of account/patta book\" document.\n",
    "\n",
    "IMPORTANT RULES:\n",
    "\n",
    "- Output JSON ONLY.\n",
    "- Do NOT invent fields.\n",
    "- Preserve values exactly as written.\n",
    "- Area must remain STRING.\n",
    "- Ignore watermark text.\n",
    "- Hobli must be extracted even if faint.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "\n",
    "{\n",
    "  \"document_metadata\": {\n",
    "    \"report_title\": null,\n",
    "    \"account_number\": null,\n",
    "    \"district\": null,\n",
    "    \"taluk\": null,\n",
    "    \"hobli\": null,\n",
    "    \"village\": null\n",
    "  },\n",
    "\n",
    "  \"entries\": [\n",
    "    {\n",
    "      \"serial_number\": null,\n",
    "      \"survey_share_number\": null,\n",
    "      \"owner_name\": null,\n",
    "      \"area\": null,\n",
    "      \"shape\": null,\n",
    "      \"local_tax\": null,\n",
    "      \"health_insurance\": null,\n",
    "      \"education_tax\": null,\n",
    "      \"total\": null\n",
    "    }\n",
    "  ],\n",
    "\n",
    "  \"footer\": {\n",
    "    \"location\": null,\n",
    "    \"date\": null,\n",
    "    \"amount\": null,\n",
    "    \"certified_copy\": null\n",
    "  }\n",
    "}\n",
    "\n",
    "Output JSON only.\n",
    "\"\"\"\n",
    "\n",
    "# ==============================\n",
    "# EXTRACTION\n",
    "# ==============================\n",
    "\n",
    "def extract_khata(pdf_data):\n",
    "\n",
    "    print(\"Extracting khata data...\")\n",
    "    result = call_gemini(pdf_data, KHATA_PROMPT)\n",
    "    data = clean_json_response(result)\n",
    "\n",
    "    # apply fixes\n",
    "    data = clean_khata_output(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "# ==============================\n",
    "# MAIN PIPELINE\n",
    "# ==============================\n",
    "\n",
    "def run_pipeline(pdf_path):\n",
    "\n",
    "    pdf_data = load_pdf_bytes(pdf_path)\n",
    "\n",
    "    result = extract_khata(pdf_data)\n",
    "\n",
    "    output_path = os.path.join(\n",
    "        os.path.dirname(pdf_path),\n",
    "        \"khata_extracted.json\"\n",
    "    )\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"Saved:\", output_path)\n",
    "\n",
    "# ==============================\n",
    "# RUN\n",
    "# ==============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"../templates/khata/khata_sample.pdf\"\n",
    "    run_pipeline(pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18452c9",
   "metadata": {},
   "source": [
    "## Sale deed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e8172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sale deed...\n",
      "Saved: ../templates/sale_deed\\sale_deed_extracted.json\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# ==============================\n",
    "# CONFIG\n",
    "# ==============================\n",
    "\n",
    "#------------ENTER YOUR API KEY HERE----------------\n",
    "# API_KEY=....\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash\"\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    MODEL_NAME,\n",
    "    generation_config={\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.1\n",
    "    }\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# JSON CLEANER\n",
    "# ==============================\n",
    "\n",
    "def clean_json_response(text):\n",
    "\n",
    "    if not text:\n",
    "        raise ValueError(\"Empty response\")\n",
    "\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"```json\", \"\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"```\", \"\", text).strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "\n",
    "    if start != -1 and end != -1:\n",
    "        return json.loads(text[start:end+1])\n",
    "\n",
    "    raise ValueError(\"Could not parse JSON\")\n",
    "\n",
    "# ==============================\n",
    "# HELPERS\n",
    "# ==============================\n",
    "\n",
    "def load_pdf_bytes(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def call_gemini(pdf_data, prompt):\n",
    "    response = model.generate_content([\n",
    "        {\"mime_type\": \"application/pdf\", \"data\": pdf_data},\n",
    "        prompt\n",
    "    ])\n",
    "    return response.text.strip()\n",
    "\n",
    "# ==============================\n",
    "# PROMPT (SALE DEED)\n",
    "# ==============================\n",
    "\n",
    "SALE_DEED_PROMPT = \"\"\"\n",
    "Extract structured information from this SALE DEED.\n",
    "\n",
    "IMPORTANT RULES:\n",
    "\n",
    "- Output JSON ONLY.\n",
    "- Do NOT invent values.\n",
    "- If field is blank in template â†’ null.\n",
    "- Preserve numbers and text exactly.\n",
    "- Do NOT summarize legal clauses.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "\n",
    "{\n",
    "  \"document_info\": {\n",
    "    \"document_type\": \"SALE DEED\",\n",
    "    \"execution_place\": null,\n",
    "    \"execution_date\": null\n",
    "  },\n",
    "\n",
    "  \"seller\": {\n",
    "    \"name\": null,\n",
    "    \"age\": null,\n",
    "    \"father_name\": null,\n",
    "    \"address\": null\n",
    "  },\n",
    "\n",
    "  \"purchaser\": {\n",
    "    \"name\": null,\n",
    "    \"age\": null,\n",
    "    \"father_name\": null,\n",
    "    \"address\": null\n",
    "  },\n",
    "\n",
    "  \"property_details\": {\n",
    "    \"apartment_number\": null,\n",
    "    \"floor\": null,\n",
    "    \"building_name\": null,\n",
    "    \"corporation_number\": null,\n",
    "    \"road\": null,\n",
    "    \"division_number\": null,\n",
    "    \"super_builtup_area\": null,\n",
    "    \"undivided_share_percent\": null,\n",
    "    \"undivided_share_area\": null\n",
    "  },\n",
    "\n",
    "  \"previous_sale_details\": {\n",
    "    \"previous_owner\": null,\n",
    "    \"previous_sale_deed_date\": null,\n",
    "    \"document_number\": null,\n",
    "    \"sub_registrar_office\": null,\n",
    "    \"khata_number\": null\n",
    "  },\n",
    "\n",
    "  \"sale_consideration\": {\n",
    "    \"amount\": null,\n",
    "    \"amount_words\": null\n",
    "  },\n",
    "\n",
    "  \"payment_details\": [\n",
    "    {\n",
    "      \"cheque_number\": null,\n",
    "      \"cheque_date\": null,\n",
    "      \"bank\": null,\n",
    "      \"amount\": null\n",
    "    }\n",
    "  ],\n",
    "\n",
    "  \"schedule_property\": {\n",
    "    \"east\": null,\n",
    "    \"west\": null,\n",
    "    \"north\": null,\n",
    "    \"south\": null\n",
    "  },\n",
    "\n",
    "  \"market_value\": null\n",
    "}\n",
    "\n",
    "Output JSON only.\n",
    "\"\"\"\n",
    "\n",
    "# ==============================\n",
    "# EXTRACTION\n",
    "# ==============================\n",
    "\n",
    "def extract_sale_deed(pdf_data):\n",
    "\n",
    "    print(\"Extracting sale deed...\")\n",
    "    result = call_gemini(pdf_data, SALE_DEED_PROMPT)\n",
    "    return clean_json_response(result)\n",
    "\n",
    "# ==============================\n",
    "# MAIN PIPELINE\n",
    "# ==============================\n",
    "\n",
    "def run_pipeline(pdf_path):\n",
    "\n",
    "    pdf_data = load_pdf_bytes(pdf_path)\n",
    "\n",
    "    result = extract_sale_deed(pdf_data)\n",
    "\n",
    "    output_path = os.path.join(\n",
    "        os.path.dirname(pdf_path),\n",
    "        \"sale_deed_extracted.json\"\n",
    "    )\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"Saved:\", output_path)\n",
    "\n",
    "# ==============================\n",
    "# RUN\n",
    "# ==============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"../templates/sale_deed/sale_deed_template.pdf\"\n",
    "    run_pipeline(pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd76532",
   "metadata": {},
   "source": [
    "## Handover Summary\n",
    "\n",
    "1. Use these extraction codes to extract the EC, khata and sale-deed of user. otherwise json formats will mismatch\n",
    "\n",
    "2. Requirements: pip install google-generativeai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_310_legal (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
